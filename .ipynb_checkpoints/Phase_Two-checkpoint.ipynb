{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e5efa5",
   "metadata": {},
   "source": [
    "### Imports:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78df391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.io import imread\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0606dff",
   "metadata": {},
   "source": [
    "### HOG feature extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75354151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(imgs, cspace='RGB', size = (64,64)):\n",
    "    features = []\n",
    "    for filename in imgs:\n",
    "        image = imread(filename)\n",
    "        if size != (64,64):\n",
    "            image = cv2.resize(image, size)\n",
    "        features.append(\n",
    "            np.ravel(\n",
    "                cv2.HOGDescriptor((64,64), (16,16), (8,8), (8,8), 9) \\\n",
    "                    .compute(get_feature_space(image, cspace))\n",
    "            )\n",
    "        )\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "949f72e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_space(img, cspace):\n",
    "    if cspace != 'RGB':\n",
    "        if cspace == 'HLS':\n",
    "            features = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif cspace == 'YCrCb':\n",
    "            features = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "        elif cspace == 'HSV':\n",
    "            features = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif cspace == 'LUV':\n",
    "            features = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif cspace == 'YUV':\n",
    "            features = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif cspace == 'Lab':\n",
    "            features = cv2.cvtColor(img, cv2.COLOR_RGB2Lab)\n",
    "        return features\n",
    "def get_hog_features(img, cspace):\n",
    "    return np.ravel(\n",
    "        cv2.HOGDescriptor((64,64), (16,16), (8,8), (8,8), 9) \\\n",
    "            .compute(get_feature_space(img, cspace))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a322fcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m         fig\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scaled_X, X_scaler\n\u001b[1;32m---> 23\u001b[0m scaled_X, X_scaler \u001b[38;5;241m=\u001b[39m \u001b[43mplot_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvehicle_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_vehicle_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mplot_features\u001b[1;34m(vehicle_features, non_vehicle_features)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_features\u001b[39m(vehicle_features, non_vehicle_features):\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mvehicle_features\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(vehicle_features) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      9\u001b[0m         X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((vehicle_features, non_vehicle_features))\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64) \n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "vehicles = glob.glob('Data/vehicles/*/*.png')\n",
    "non_vehicles = glob.glob('Data/non-vehicles/*/*.png')\n",
    "vehicle_features = extract_features(vehicles, cspace='YUV')\n",
    "non_vehicle_features = extract_features(non_vehicles, cspace='YUV')\n",
    "\n",
    "def plot_features(vehicle_features, non_vehicle_features):\n",
    "    vehicle_features[0].shape\n",
    "    if len(vehicle_features) > 0:\n",
    "        X = np.vstack((vehicle_features, non_vehicle_features)).astype(np.float64) \n",
    "        X_scaler = StandardScaler().fit(X)\n",
    "        scaled_X = X_scaler.transform(X)\n",
    "        vehicle_ind = np.random.randint(0, len(vehicles))\n",
    "        fig = plt.figure(figsize=(12,4))\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(mpimg.imread(vehicles[vehicle_ind]))\n",
    "        plt.title('original image')\n",
    "        plt.subplot(132)\n",
    "        plt.plot(scaled_X[vehicle_ind])\n",
    "        plt.title('scaled features')\n",
    "        fig.tight_layout()\n",
    "    return scaled_X, X_scaler\n",
    "        \n",
    "scaled_X, X_scaler = plot_features(vehicle_features, non_vehicle_features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f150ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee49743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#horizontal stack ones for cars and otherwise zero\n",
    "labels = np.hstack((np.ones(len(vehicle_features)), np.zeros(len(non_vehicle_features))))\n",
    "#20% test images \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, labels, test_size=0.2, random_state=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277f4b17",
   "metadata": {},
   "source": [
    "__Training model with MLP__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "801fe312",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MLPClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f8cd734e8994>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Multi-layer Perceptron classifier model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m999\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MLP results'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MLPClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "#Multi-layer Perceptron classifier model\n",
    "\n",
    "mlp = MLPClassifier(random_state=999)\n",
    "mlp.fit(X_train, y_train)\n",
    "print('MLP results')\n",
    "print('accuracy on training data: ', mlp.score(X_train, y_train))\n",
    "print('accuracy on test data: ', mlp.score(X_test, y_test))\n",
    "prediction = mlp.predict(X_test[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239a4474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving trained data \n",
    "joblib.dump(mlp, 'mlp1.pkl')\n",
    "joblib.dump(X_scaler, 'scaler1.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ad0fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading trained data file \n",
    "mlp = joblib.load('mlp1.pkl')\n",
    "X_scaler = joblib.load('scaler1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f296e0",
   "metadata": {},
   "source": [
    "__Sliding Window__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a9c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.75, 0.75)):\n",
    "    if x_start_stop[0] == None: # start from the left\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None: # stop at the left\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:# start from the bottom\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None: # stop at the top\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    xspan = x_start_stop[1] - x_start_stop[0] # span size horizontally\n",
    "    yspan = y_start_stop[1] - y_start_stop[0] # span size vertically\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))  #the part of the window without overlapping horizontally\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))  #the part of the window without overlapping vertically\n",
    "    \n",
    "    nx_windows = np.int(xspan/nx_pix_per_step) # number of windows horizontally\n",
    "    \n",
    "    ny_windows = np.int(yspan/ny_pix_per_step) #number of windows vertically\n",
    "    window_list = []\n",
    "    # scan the span from left to right and from top to bottom\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = (xs+1)*nx_pix_per_step + x_start_stop[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = (ys+1)*ny_pix_per_step + y_start_stop[0]\n",
    "            # append the top left and bottom right corner points of each window\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    return window_list # list of all the window coordinates in the span"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f607dc21",
   "metadata": {},
   "source": [
    "### car detection using the sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c2113bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_img(path):\n",
    "\n",
    "    image = imread(path)\n",
    "    detected_vehicles = [] \n",
    "    pxs = 320            # window starting size \n",
    "    PXS_LIMIT = 720      # max window size\n",
    "    y_start_stop = [400, 660]    #search in the lower part of the image to decrease the time \n",
    "    xy_overlap = (0.8, 0.8)      #propability of overlapped = 80% \n",
    "    ACCEPTANCE_THRESHOLD = .98   # the accuracy = 98% \n",
    "    INCREMENT_PXS_BY = 16        #window increasing step \n",
    "    while pxs < PXS_LIMIT:       #check if window size is smaller than the max window size\n",
    "        windows = slide_window(  #call the sliding window function to return list of the windows coordinates \n",
    "            image, \n",
    "            x_start_stop=[640, None], \n",
    "            y_start_stop=y_start_stop, \n",
    "            xy_window=(pxs, pxs), \n",
    "            xy_overlap=xy_overlap\n",
    "        )  \n",
    "        for w in windows: #loop inside the windows list to get the target windows which containg vehicles \n",
    "            features = []\n",
    "            resized = cv2.resize(  # resize the window to (64*64) to get the feature vector \n",
    "                (\n",
    "                    image[w[0][1]: w[1][1], w[0][0]: w[1][0]]\n",
    "                ),(64,64)\n",
    "            )\n",
    "            \n",
    "            hf = get_hog_features(resized, cspace='YUV')\n",
    "            x_scaled = X_scaler.transform(hf.reshape(1, -1))\n",
    "            if resized.shape[0] > 0: #check that the width of the window isnt equal 0 \n",
    "                if mlp.predict_proba(x_scaled.reshape(1,-1))[0][1] > ACCEPTANCE_THRESHOLD: \n",
    "                    #checking if the window feature vector is matching with the model \n",
    "                    #then , adding the window to detected_vehicles list  \n",
    "                    detected_vehicles.append(w)\n",
    "        pxs += INCREMENT_PXS_BY #finally at the end of the loop increment the window dimensions with 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0462c4",
   "metadata": {},
   "source": [
    "### car detection using the sliding window for videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3769dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vid(image):\n",
    "    \n",
    "    detected_vehicles = [] \n",
    "    pxs = 320            # window starting size \n",
    "    PXS_LIMIT = 720      # max window size\n",
    "    y_start_stop = [400, 660]    #search in the lower part of the image to decrease the time \n",
    "    xy_overlap = (0.8, 0.8)      #propability of overlapped = 80% \n",
    "    ACCEPTANCE_THRESHOLD = .98   # the accuracy = 98% \n",
    "    INCREMENT_PXS_BY = 16        #window increasing step \n",
    "    while pxs < PXS_LIMIT:       #check if window size is smaller than the max window size\n",
    "        windows = slide_window(  #call the sliding window function to return list of the windows coordinates \n",
    "            image, \n",
    "            x_start_stop=[640, None], \n",
    "            y_start_stop=y_start_stop, \n",
    "            xy_window=(pxs, pxs), \n",
    "            xy_overlap=xy_overlap\n",
    "        )  \n",
    "        for w in windows: #loop inside the windows list to get the target windows which containg vehicles \n",
    "            features = []\n",
    "            resized = cv2.resize(  # resize the window to (64*64) to get the feature vector \n",
    "                (\n",
    "                    image[w[0][1]: w[1][1], w[0][0]: w[1][0]]\n",
    "                ),(64,64)\n",
    "            )\n",
    "            \n",
    "            hf = get_hog_features(resized, cspace='YUV')\n",
    "            x_scaled = X_scaler.transform(hf.reshape(1, -1))\n",
    "            if resized.shape[0] > 0: #check that the width of the window isnt equal 0 \n",
    "                if mlp.predict_proba(x_scaled.reshape(1,-1))[0][1] > ACCEPTANCE_THRESHOLD: \n",
    "                    #checking if the window feature vector is matching with the model \n",
    "                    #then , adding the window to detected_vehicles list  \n",
    "                    detected_vehicles.append(w)\n",
    "        pxs += INCREMENT_PXS_BY #finally at the end of the loop increment the window dimensions with 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed61b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
