{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lane_detector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fyhO0QTG_dmV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b6be1c3-070d-4600-b9f7-600210663fb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2408448/45929032 bytes (5.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5210112/45929032 bytes (11.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b8085504/45929032 bytes (17.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11149312/45929032 bytes (24.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b13910016/45929032 bytes (30.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b17129472/45929032 bytes (37.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20340736/45929032 bytes (44.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23601152/45929032 bytes (51.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b26779648/45929032 bytes (58.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b29999104/45929032 bytes (65.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b33243136/45929032 bytes (72.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b36708352/45929032 bytes (79.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b40034304/45929032 bytes (87.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b43335680/45929032 bytes (94.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from moviepy.editor import VideoFileClip\n",
        "import matplotlib.image as mpimg\n",
        "from skimage import io\n",
        "from moviepy.editor import VideoFileClip\n",
        "from IPython.display import HTML\n",
        "from PIL import Image\n",
        "from moviepy.editor import *\n",
        "import os\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter\n"
      ],
      "metadata": {
        "id": "r4qCbSMt_p-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
        "\n",
        "    # Apply threshold\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    # Apply x or y gradient with the OpenCV Sobel() function\n",
        "    # and take the absolute value\n",
        "    if orient == 'x':\n",
        "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
        "    if orient == 'y':\n",
        "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
        "    # Rescale back to 8 bit integer\n",
        "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
        "    # Create a copy and apply the threshold\n",
        "    binary_output = np.zeros_like(scaled_sobel)\n",
        "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
        "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
        "\n",
        "    # Return the result\n",
        "    return binary_output# retuen  x or y\n",
        "\n",
        "\n",
        "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
        "\n",
        "    # Apply threshold\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    # Take both Sobel x and y gradients\n",
        "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
        "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
        "    # Calculate the gradient magnitude\n",
        "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
        "    # Rescale to 8 bit\n",
        "    scale_factor = np.max(gradmag)/255 \n",
        "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
        "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
        "    binary_output = np.zeros_like(gradmag)\n",
        "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
        "\n",
        "    # Return the binary image\n",
        "    return binary_output\n",
        "\n",
        "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
        "\n",
        "    # Apply threshold\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    # Calculate the x and y gradients\n",
        "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
        "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
        "    # Take the absolute value of the gradient direction, \n",
        "    # apply a threshold, and create a binary image result\n",
        "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
        "    binary_output =  np.zeros_like(absgraddir)\n",
        "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
        "\n",
        "    # Return the binary image\n",
        "    return binary_output\n",
        "def combined_thresholds(image, ksize = 3):\n",
        "    # Choose a Sobel kernel size\n",
        "\n",
        "    # Apply each of the thresholding functions\n",
        "    gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=ksize, thresh=(5, 100))\n",
        "    grady = abs_sobel_thresh(image, orient='y', sobel_kernel=ksize, thresh=(5, 100))\n",
        "    #c= cv2.bitwise_or(gradx,grady)\n",
        "    \n",
        "    mag_binary = mag_thresh(image, sobel_kernel=ksize, mag_thresh=(3, 255))\n",
        "    dir_binary = dir_threshold(image, sobel_kernel=ksize, thresh=(0*np.pi/180, 90*np.pi/180)) \n",
        "    combined = np.zeros_like(dir_binary, np.uint8)    \n",
        "    #combined[((gradx == 1) ) ] = 1\n",
        "    combined[((gradx == 1) ) & ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
        "    #combined[ (mag_binary == 1) ] = 1\n",
        "\n",
        "    return combined\n",
        "\n",
        "def filter(image):\n",
        "    \n",
        "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
        "    s_channel = hls[:,:,2]\n",
        "    l_channel = hls[:,:,1]\n",
        "\n",
        "    sxbinary = combined_thresholds(image)\n",
        "\n",
        "\n",
        "    # Threshold color channel\n",
        "    s_thresh_min = 40\n",
        "    s_thresh_max = 255\n",
        "    l_thresh_min = 150\n",
        "    l_thresh_max = 255  \n",
        "    \n",
        "    \n",
        "    s_binary = np.zeros_like(s_channel)\n",
        "    s_binary[((s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)) ] = 1\n",
        "    \n",
        "    l_binary = np.zeros_like(s_channel)\n",
        "    l_binary[((l_channel >= l_thresh_min) & (l_channel <= l_thresh_max))] = 1\n",
        "\n",
        "    # Combine the two binary thresholds\n",
        "    combined_binary = np.zeros_like(sxbinary)\n",
        "    #combined_binary [(l_binary == 1)& (sxbinary == 1)] = 1\n",
        "    combined_binary[((s_binary == 1) & (sxbinary == 1)) | ((sxbinary == 1) & (l_binary == 1))] = 1\n",
        "    \n",
        "    return combined_binary\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HoxLwGnsOM88"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Warp\n"
      ],
      "metadata": {
        "id": "XApG9Z2R_1TF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def warp(image,state='in'):\n",
        "\n",
        "    src = np.float32([[570,460],[image.shape[1] - 573,460],[image.shape[1] - 150,image.shape[0]],[150,image.shape[0]]])\n",
        "    dst = np.float32([[200,0],[image.shape[1]-200,0],[image.shape[1]-200,image.shape[0]],[200,image.shape[0]]])\n",
        "    if state == 'in':\n",
        "        M = cv2.getPerspectiveTransform(src, dst)\n",
        "    if state == 'out':\n",
        "        M = cv2.getPerspectiveTransform(dst, src)\n",
        "    \n",
        "    warped = cv2.warpPerspective(image, M, (image.shape[1],image.shape[0]), flags=cv2.INTER_LINEAR)\n",
        "    return warped\n",
        "\n"
      ],
      "metadata": {
        "id": "tez8aSId_28k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detector\n"
      ],
      "metadata": {
        "id": "VlNqVs84AOmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LaneDetector:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.detected = True\n",
        "        self.left_lane_inds = []  # Create empty lists to receive left and right lane pixel indices\n",
        "        self.right_lane_inds = []\n",
        "        \n",
        "        self.n_frames = 10\n",
        "        \n",
        "        # x values of the last n fits of the line\n",
        "        self.recent_xfitted = [] \n",
        "        #average x values of the fitted line over the last n iterations\n",
        "        self.bestx = [np.zeros_like(720, np.float32), np.zeros_like(720, np.float32)]\n",
        "        \n",
        "        # coefficient values of the last n fits of the line\n",
        "        self.recent_coefficients = []\n",
        "        \n",
        "        #polynomial coefficients averaged over the last n iterations\n",
        "        self.best_fit = [0,0,0]\n",
        "        \n",
        "        self.vehicle_offset = 0.0\n",
        "        self.avg_curverad = 1000\n",
        "\n",
        "    def draw_lane(self, orignal_image, binary_warped, filtered_binary):    \n",
        "        \n",
        "        nonzero = binary_warped.nonzero()  # Identify the x and y positions of all nonzero pixels in the image\n",
        "        nonzeroy = np.array(nonzero[0])\n",
        "        nonzerox = np.array(nonzero[1])\n",
        "        \n",
        "        # Create an output image to draw on and  visualize the result\n",
        "       # out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
        "         \n",
        "        margin = 50   \n",
        "        # Set minimum number of pixels found to recenter window   \n",
        "        minpix = 50\n",
        "        \n",
        "        if self.detected:\n",
        "            # Take a histogram of the bottom half of the image\n",
        "            histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
        "\n",
        "            # Find the peak of the left and right halves of the histogram\n",
        "            # These will be the starting point for the left and right lines\n",
        "            midpoint = np.int(histogram.shape[0]/2)\n",
        "            leftx_base = np.argmax(histogram[:midpoint])\n",
        "            rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
        "\n",
        "            nwindows = 9  # Choose the number of sliding windows\n",
        "            window_height = np.int((binary_warped.shape[0])/nwindows)   # Set height of windows\n",
        "\n",
        "            leftx_current = leftx_base   # Current positions to be updated for each window\n",
        "            rightx_current = rightx_base   # Set the width of the windows +/- margin\n",
        "            \n",
        "            left_lane_inds = []\n",
        "            right_lane_inds = []\n",
        "\n",
        "            # Step through the windows one by one\n",
        "            for window in range(nwindows):\n",
        "\n",
        "                # Identify window boundaries in x and y (and right and left)\n",
        "                win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
        "                win_y_high = binary_warped.shape[0] - window*window_height\n",
        "                win_xleft_low = leftx_current - margin\n",
        "                win_xleft_high = leftx_current + margin\n",
        "                win_xright_low = rightx_current - margin\n",
        "                win_xright_high = rightx_current + margin\n",
        "\n",
        "                # Identify the nonzero pixels in x and y within the window\n",
        "                good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
        "                                  (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
        "                good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
        "                                   (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
        "            \n",
        "                # Append these indices to the lists\n",
        "                left_lane_inds.append(good_left_inds)\n",
        "                right_lane_inds.append(good_right_inds)\n",
        "                # If you found > minpix pixels, recenter next window on their mean position\n",
        "                if len(good_left_inds) > minpix:\n",
        "                    leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
        "                if len(good_right_inds) > minpix:        \n",
        "                    rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
        "\n",
        "            # Concatenate the arrays of indices\n",
        "            self.left_lane_inds = np.concatenate(left_lane_inds)\n",
        "            self.right_lane_inds = np.concatenate(right_lane_inds)\n",
        "        else:\n",
        "            self.left_lane_inds = ((nonzerox > (self.best_fit[0][0]*(nonzeroy**2) + self.best_fit[0][1]*nonzeroy + \n",
        "                                    self.best_fit[0][2] - margin)) & (nonzerox < (self.best_fit[0][0]*(nonzeroy**2) + \n",
        "                                    self.best_fit[0][1]*nonzeroy + self.best_fit[0][2] + margin))) \n",
        "            self.right_lane_inds = ((nonzerox > (self.best_fit[1][0]*(nonzeroy**2) + self.best_fit[1][1]*nonzeroy + \n",
        "                                    self.best_fit[1][2] - margin)) & (nonzerox < (self.best_fit[1][0]*(nonzeroy**2) + \n",
        "                                    self.best_fit[1][1]*nonzeroy + self.best_fit[1][2] + margin)))\n",
        "              #self.left_lane_inds = ((nonzerox > (self.left_fit[0]*(nonzeroy**2) + self.left_fit[1]*nonzeroy + \n",
        "              #                       self.left_fit[2] - margin)) & (nonzerox < (self.left_fit[0]*(nonzeroy**2) + \n",
        "              #                       self.left_fit[1]*nonzeroy + self.left_fit[2] + margin))) \n",
        "              # self.right_lane_inds = ((nonzerox > (self.right_fit[0]*(nonzeroy**2) + self.right_fit[1]*nonzeroy + \n",
        "              #                       self.right_fit[2] - margin)) & (nonzerox < (self.right_fit[0]*(nonzeroy**2) + \n",
        "              #                       self.right_fit[1]*nonzeroy + self.right_fit[2] + margin)))\n",
        "        \n",
        "        # Again, extract left and right line pixel positions\n",
        "        leftx = nonzerox[self.left_lane_inds]\n",
        "        lefty = nonzeroy[self.left_lane_inds] \n",
        "        rightx = nonzerox[self.right_lane_inds]\n",
        "        righty = nonzeroy[self.right_lane_inds]\n",
        "        \n",
        "        ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
        "\n",
        "        # Fit a second order polynomial to each\n",
        "        if lefty.shape[0] >= 400 and righty.shape[0] >= 400 and leftx.shape[0] >= 400 and rightx.shape[0] >= 400:\n",
        "            self.detected = False\n",
        "            self.left_fit = np.polyfit(lefty, leftx, 2)\n",
        "            self.right_fit = np.polyfit(righty, rightx, 2)\n",
        "            \n",
        "            \n",
        "            if len(self.recent_coefficients) >= self.n_frames:\n",
        "                self.recent_coefficients.pop(0)\n",
        "            self.recent_coefficients.append([self.left_fit, self.right_fit])\n",
        "\n",
        "            self.best_fit = [0,0,0]\n",
        "            for coefficient in self.recent_coefficients:\n",
        "                self.best_fit[0] = self.best_fit[0] + coefficient[0]\n",
        "                self.best_fit[1] = self.best_fit[1] + coefficient[1]\n",
        "\n",
        "            self.best_fit[0] = self.best_fit[0]/len(self.recent_coefficients)\n",
        "            self.best_fit[1] = self.best_fit[1]/len(self.recent_coefficients)\n",
        "\n",
        "\n",
        "            # Generate x and y values for plotting\n",
        "            left_fitx = self.best_fit[0][0]*ploty**2 + self.best_fit[0][1]*ploty + self.best_fit[0][2]\n",
        "            right_fitx = self.best_fit[1][0]*ploty**2 + self.best_fit[1][1]*ploty + self.best_fit[1][2]\n",
        "            #left_fitx = self.left_fit[0]*ploty**2 + self.left_fit[1]*ploty + self.left_fit[2]\n",
        "            # right_fitx = self.right_fit[0]*ploty**2 + self.right_fit[1]*ploty + self.right_fit[2]\n",
        "\n",
        "            if len(self.recent_xfitted) >= self.n_frames:\n",
        "                self.recent_xfitted.pop(0)\n",
        "\n",
        "\n",
        "            self.recent_xfitted.append([left_fitx, right_fitx])\n",
        "\n",
        "\n",
        "            self.bestx = [np.zeros_like(720, np.float32), np.zeros_like(720, np.float32)]\n",
        "            for fit in self.recent_xfitted:\n",
        "                self.bestx[0] = self.bestx[0] + fit[0]\n",
        "                self.bestx[1] = self.bestx[1] + fit[1]\n",
        "\n",
        "            self.bestx[0] = self.bestx[0]/len(self.recent_xfitted)\n",
        "            self.bestx[1] = self.bestx[1]/len(self.recent_xfitted)\n",
        "                     \n",
        "            \n",
        "        else:\n",
        "            self.detected = True\n",
        "        \n",
        "        \n",
        "        \n",
        "        # Create an image to draw on and an image to show the selection window\n",
        "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
        "        \n",
        "        \n",
        "        window_img = np.zeros_like(out_img)\n",
        "        # Color in left and right line pixels\n",
        "      #  out_img[nonzeroy[self.left_lane_inds], nonzerox[self.left_lane_inds]] = [255, 0, 0]\n",
        "      #  out_img[nonzeroy[self.right_lane_inds], nonzerox[self.right_lane_inds]] = [0, 0, 255]\n",
        "        \n",
        "\n",
        "        # Generate a polygon to illustrate the search window area\n",
        "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
        "        margin = 5\n",
        "        left_line_window1 = np.array([np.transpose(np.vstack([self.bestx[0]-margin, ploty]))])\n",
        "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([self.bestx[0]+margin, \n",
        "                                      ploty])))])\n",
        "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
        "\n",
        "        right_line_window1 = np.array([np.transpose(np.vstack([self.bestx[1]-margin, ploty]))])\n",
        "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([self.bestx[1]+margin, \n",
        "                                      ploty])))])\n",
        "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
        "\n",
        "\n",
        "        center_line_window1 = np.array([np.transpose(np.vstack([self.bestx[0]+margin, ploty]))])\n",
        "        center_line_window2 = np.array([np.flipud(np.transpose(np.vstack([self.bestx[1]-margin, ploty])))])\n",
        "        center_line_pts = np.hstack((center_line_window1,center_line_window2))\n",
        "\n",
        "\n",
        "        # Draw the lane onto the warped blank image\n",
        "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (255,255, 0))\n",
        "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,0, 255))\n",
        "        cv2.fillPoly(window_img, np.int_([center_line_pts]), (0,255, 0))\n",
        "\n",
        "        window_img_unwrapped = warp(window_img,state = 'out')\n",
        "\n",
        "        result = cv2.addWeighted(orignal_image, 1, window_img_unwrapped, 0.3, 0)\n",
        "      #bouns \n",
        "        if leftx.shape[0] >= ploty.shape[0] and rightx.shape[0] >= ploty.shape[0] :\n",
        "            leftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
        "            rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
        "\n",
        "            # Define conversions in x and y from pixels space to meters\n",
        "            ym_per_pix = 30/binary_warped.shape[0] # meters per pixel in y dimension\n",
        "            xm_per_pix = 3.7/binary_warped.shape[1] # meters per pixel in x dimension\n",
        "\n",
        "            self.vehicle_offset = ((binary_warped.shape[1]/2) - (((rightx[0] - leftx[0])/2) + leftx[0]))*xm_per_pix\n",
        "            \n",
        "\n",
        "            leftx = leftx[:len(ploty)]\n",
        "            rightx = rightx[:len(ploty)]\n",
        "\n",
        "            y_eval = np.max(ploty)\n",
        "            \n",
        "            # Fit new polynomials to x,y in world space\n",
        "            left_fit_cr = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
        "            right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
        "            # Calculate the new radii of curvature\n",
        "            left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
        "            right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
        "            # Now our radius of curvature is in meters\n",
        "            self.avg_curverad = (left_curverad + right_curverad) / 2\n",
        "            \n",
        "        cv2.putText(result, 'Vehicle is ' + str(-self.vehicle_offset)[0:5] + 'm left of center', (30,140), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2)\n",
        "        cv2.putText(result, 'Radius of Curvature = ' + str(int(np.round(self.avg_curverad))) + '(m)', (30,80), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2)\n",
        "    \n",
        "        \n",
        "        return result,window_img\n"
      ],
      "metadata": {
        "id": "3QzLWu6mAREB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lane_detector = LaneDetector()\n",
        "draw_lane = lane_detector.draw_lane\n",
        "def process_image(image):\n",
        "   \n",
        "    filtered_binary = filter(image)\n",
        "    binary_warped = warp(filtered_binary)\n",
        "    result,wind = draw_lane(image, binary_warped, filtered_binary)\n",
        "    #result= draw_Lane(binary_warped,Minv,image)\n",
        "    \n",
        "    return result\n"
      ],
      "metadata": {
        "id": "mOHbpgs13PPx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAin\n"
      ],
      "metadata": {
        "id": "agA7RBaFAW96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "white_output = '/content/filter.mp4'\n",
        "clip1 = VideoFileClip(\"/content/challenge_video.mp4\")\n",
        "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
        "%time white_clip.write_videofile(white_output, audio=False)"
      ],
      "metadata": {
        "id": "olyFBju1RwMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lane_detector = LaneDetector()\n",
        "# draw_lane = lane_detector.draw_lane\n",
        "# def process_image(image):\n",
        "#     filtered_binary = filter(image)\n",
        "#     binary_warped = warp(filtered_binary)\n",
        "#     final_image = draw_lane(image, binary_warped, filtered_binary)\n",
        "#     return final_image\n",
        "\n",
        "print(\"nn\")\n",
        "\n",
        "\n",
        "# def warped(image):\n",
        "#   filtered_binary = filter(image)\n",
        "#   binary_warped = warp(filtered_binary)\n",
        "#   return binary_warped\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# white_output = '/content/warp.mp4'\n",
        "# clip1 = VideoFileClip(\"/content/challenge_video.mp4\")\n",
        "# white_clip = clip1.fl_image(warped) #NOTE: this function expects color images!!\n",
        "# %time white_clip.write_videofile(white_output, audio=False)\n",
        "\n",
        "# white_output = '/content/Lane_Detector.mp4'\n",
        "# clip1 = VideoFileClip(\"/content/challenge_video.mp4\")\n",
        "# white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
        "# %time white_clip.write_videofile(white_output, audio=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI_ijYG7AY8A",
        "outputId": "0fdbe83f-f295-4c57-cfc8-282f4774891a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nn\n",
            "[MoviePy] >>>> Building video /content/filter.mp4\n",
            "[MoviePy] Writing video /content/filter.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 485/485 [01:52<00:00,  4.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: /content/filter.mp4 \n",
            "\n",
            "CPU times: user 1min 53s, sys: 3.35 s, total: 1min 57s\n",
            "Wall time: 1min 55s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MOwDgJksAWXT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "b61c2254-79d2-4068-92dc-72fd69e09fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-b376724d4378>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    print(\"Error opening video file\")\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    }
  ]
}